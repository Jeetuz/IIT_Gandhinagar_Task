{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross-Validation Results:\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "  Accuracy: 0.9810\n",
      "  Precision: 0.9810\n",
      "  Recall: 0.9810\n",
      "  F1 Score: 0.9810\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "\n",
      "  Accuracy: 0.9368\n",
      "  Precision: 0.9370\n",
      "  Recall: 0.9368\n",
      "  F1 Score: 0.9368\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "\n",
      "  Accuracy: 0.9834\n",
      "  Precision: 0.9835\n",
      "  Recall: 0.9834\n",
      "  F1 Score: 0.9834\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "\n",
      "  Accuracy: 0.5449\n",
      "  Precision: 0.3502\n",
      "  Recall: 0.5449\n",
      "  F1 Score: 0.4093\n",
      "\n",
      "\n",
      "Leave-One-Subject-Out Cross-Validation Results:\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "  Accuracy: 0.9132\n",
      "  Precision: 0.9242\n",
      "  Recall: 0.9132\n",
      "  F1 Score: 0.9046\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "\n",
      "  Accuracy: 0.8515\n",
      "  Precision: 0.8658\n",
      "  Recall: 0.8515\n",
      "  F1 Score: 0.8459\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "\n",
      "  Accuracy: 0.9397\n",
      "  Precision: 0.9467\n",
      "  Recall: 0.9397\n",
      "  F1 Score: 0.9352\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "\n",
      "  Accuracy: 0.5444\n",
      "  Precision: 0.3486\n",
      "  Recall: 0.5444\n",
      "  F1 Score: 0.4085\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_features_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\train\\X_train.txt\"\n",
    "train_labels_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\train\\y_train.txt\"\n",
    "test_features_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\test\\X_test.txt\"\n",
    "test_labels_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\test\\y_test.txt\"\n",
    "\n",
    "X_train = pd.read_csv(train_features_path, delim_whitespace=True, header=None)\n",
    "y_train = pd.read_csv(train_labels_path, delim_whitespace=True, header=None).squeeze()\n",
    "X_test = pd.read_csv(test_features_path, delim_whitespace=True, header=None)\n",
    "y_test = pd.read_csv(test_labels_path, delim_whitespace=True, header=None).squeeze()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=500),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score,\n",
    "    \"Precision\": precision_score,\n",
    "    \"Recall\": recall_score,\n",
    "    \"F1 Score\": f1_score\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"K-Fold Cross-Validation Results:\\n\")\n",
    "for model_name, model in models.items():\n",
    "    scores = {\n",
    "        \"Accuracy\": [],\n",
    "        \"Precision\": [],\n",
    "        \"Recall\": [],\n",
    "        \"F1 Score\": []\n",
    "    }\n",
    "    for train_idx, test_idx in kfold.split(X_train, y_train):\n",
    "        X_ktrain, X_ktest = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_ktrain, y_ktest = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_ktrain, y_ktrain)\n",
    "        y_pred = model.predict(X_ktest)\n",
    "\n",
    "        for metric_name, metric_func in metrics.items():\n",
    "            if metric_name == \"Accuracy\":\n",
    "                scores[metric_name].append(metric_func(y_ktest, y_pred))\n",
    "            else:\n",
    "                scores[metric_name].append(metric_func(y_ktest, y_pred, average=\"weighted\"))\n",
    "\n",
    "    print(f\"{model_name}:\\n\")\n",
    "    for metric_name in metrics.keys():\n",
    "        print(f\"  {metric_name}: {np.mean(scores[metric_name]):.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "subject_train_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\train\\subject_train.txt\"\n",
    "subjects = pd.read_csv(subject_train_path, delim_whitespace=True, header=None).squeeze()\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "print(\"Leave-One-Subject-Out Cross-Validation Results:\\n\")\n",
    "for model_name, model in models.items():\n",
    "    scores = {\n",
    "        \"Accuracy\": [],\n",
    "        \"Precision\": [],\n",
    "        \"Recall\": [],\n",
    "        \"F1 Score\": []\n",
    "    }\n",
    "    for train_idx, test_idx in logo.split(X_train, y_train, groups=subjects):\n",
    "        X_ltrain, X_ltest = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_ltrain, y_ltest = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_ltrain, y_ltrain)\n",
    "        y_pred = model.predict(X_ltest)\n",
    "\n",
    "        for metric_name, metric_func in metrics.items():\n",
    "            if metric_name == \"Accuracy\":\n",
    "                scores[metric_name].append(metric_func(y_ltest, y_pred))\n",
    "            else:\n",
    "                scores[metric_name].append(metric_func(y_ltest, y_pred, average=\"weighted\"))\n",
    "\n",
    "    print(f\"{model_name}:\\n\")\n",
    "    for metric_name in metrics.keys():\n",
    "        print(f\"  {metric_name}: {np.mean(scores[metric_name]):.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_features_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\train\\X_train.txt\"\n",
    "train_labels_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\train\\y_train.txt\"\n",
    "test_features_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\test\\X_test.txt\"\n",
    "test_labels_path = r\"C:\\Users\\Jeet\\Desktop\\IIT_Gandhinagar\\Dataset_Folder\\UCI HAR Dataset\\UCI HAR Dataset\\test\\y_test.txt\"\n",
    "\n",
    "X_train = pd.read_csv(train_features_path, delim_whitespace=True, header=None)\n",
    "y_train = pd.read_csv(train_labels_path, delim_whitespace=True, header=None).squeeze()\n",
    "X_test = pd.read_csv(test_features_path, delim_whitespace=True, header=None)\n",
    "y_test = pd.read_csv(test_labels_path, delim_whitespace=True, header=None).squeeze()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=500),\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "ada_boost_model = AdaBoostClassifier(base_estimator=base_estimator, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'base_estimator__max_depth': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# GridSearchCV for AdaBoost hyperparameter tuning\n",
    "grid_search = GridSearchCV(ada_boost_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_adaboost = grid_search.best_estimator_\n",
    "models[\"AdaBoost\"] = best_adaboost\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score,\n",
    "    \"Precision\": precision_score,\n",
    "    \"Recall\": recall_score,\n",
    "    \"F1 Score\": f1_score\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"K-Fold Cross-Validation Results:\\n\")\n",
    "for model_name, model in models.items():\n",
    "    scores = {\n",
    "        \"Accuracy\": [],\n",
    "        \"Precision\": [],\n",
    "        \"Recall\": [],\n",
    "        \"F1 Score\": []\n",
    "    }\n",
    "    for train_idx, test_idx in kfold.split(X_train, y_train):\n",
    "        X_ktrain, X_ktest = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_ktrain, y_ktest = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_ktrain, y_ktrain)\n",
    "        y_pred = model.predict(X_ktest)\n",
    "\n",
    "        for metric_name, metric_func in metrics.items():\n",
    "            if metric_name == \"Accuracy\":\n",
    "                scores[metric_name].append(metric_func(y_ktest, y_pred))\n",
    "            else:\n",
    "                scores[metric_name].append(metric_func(y_ktest, y_pred, average=\"weighted\"))\n",
    "\n",
    "    print(f\"{model_name}:\\n\")\n",
    "    for metric_name in metrics.keys():\n",
    "        print(f\"  {metric_name}: {np.mean(scores[metric_name]):.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Leave-One-Subject-Out Cross-Validation\n",
    "subject_train_path = \"Dataset_Folder/UCI HAR Dataset/UCI HAR Dataset/train/subject_train.txt\"\n",
    "subjects = pd.read_csv(subject_train_path, delim_whitespace=True, header=None).squeeze()\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "print(\"Leave-One-Subject-Out Cross-Validation Results:\\n\")\n",
    "for model_name, model in models.items():\n",
    "    scores = {\n",
    "        \"Accuracy\": [],\n",
    "        \"Precision\": [],\n",
    "        \"Recall\": [],\n",
    "        \"F1 Score\": []\n",
    "    }\n",
    "    for train_idx, test_idx in logo.split(X_train, y_train, groups=subjects):\n",
    "        X_ltrain, X_ltest = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_ltrain, y_ltest = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_ltrain, y_ltrain)\n",
    "        y_pred = model.predict(X_ltest)\n",
    "\n",
    "        for metric_name, metric_func in metrics.items():\n",
    "            if metric_name == \"Accuracy\":\n",
    "                scores[metric_name].append(metric_func(y_ltest, y_pred))\n",
    "            else:\n",
    "                scores[metric_name].append(metric_func(y_ltest, y_pred, average=\"weighted\"))\n",
    "\n",
    "    print(f\"{model_name}:\\n\")\n",
    "    for metric_name in metrics.keys():\n",
    "        print(f\"  {metric_name}: {np.mean(scores[metric_name]):.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Evaluation on Test Set with Best AdaBoost Model:\\n\")\n",
    "y_pred = best_adaboost.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
